{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, recall_score, precision_score, classification_report, mean_squared_error\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "from yellowbrick.style import set_palette\n",
    "from yellowbrick.features import RadViz\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', 'FutureWarning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV\n",
    "survey = pd.read_csv('Data/survey.csv')\n",
    "indicators = pd.read_csv('Data/raw_data/Development_Indicators.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of required 'Series Name' values\n",
    "required_series = [\n",
    "    \"Coverage of social insurance programs (% of population)\",\n",
    "    \"Coverage of social protection and labor programs (% of population)\",\n",
    "    \"Coverage of unemployment benefits and ALMP (% of population)\",\n",
    "    \"Educational attainment, at least completed primary, population 25+ years, total (%) (cumulative)\",\n",
    "    \"Employment to population ratio, 15+, female (%) (national estimate)\",\n",
    "    \"Employment to population ratio, 15+, male (%) (national estimate)\",\n",
    "    \"GDP per capita (current US$)\",\n",
    "    \"Labor force participation rate, female (% of female population ages 15+) (national estimate)\",\n",
    "    \"Labor force participation rate, male (% of male population ages 15+) (national estimate)\",\n",
    "    \"Labor force participation rate, total (% of total population ages 15+) (national estimate)\",\n",
    "    \"Labor force with basic education (% of total working-age population with basic education)\",\n",
    "    \"Labor force with basic education, female (% of female working-age population with basic education)\",\n",
    "    \"Life expectancy at birth, female (years)\",\n",
    "    \"Life expectancy at birth, total (years)\",\n",
    "    \"Population, total\",\n",
    "    \"Suicide mortality rate (per 100,000 population)\",\n",
    "    \"Suicide mortality rate, female (per 100,000 female population)\",\n",
    "    \"Suicide mortality rate, male (per 100,000 male population)\",\n",
    "    \"Unemployment with basic education (% of total labor force with basic education)\",\n",
    "    \"Unemployment with basic education, female (% of female labor force with basic education)\",\n",
    "    \"Unemployment with basic education, male (% of male labor force with basic education)\"\n",
    "]\n",
    "\n",
    "# Filter the dataset using the list of required 'Series Name' values\n",
    "indicator_filter = indicators[indicators['Series Name'].isin(required_series)]\n",
    "\n",
    "# Create a mapping for renaming the columns\n",
    "column_rename_mapping = {f\"{year} [YR{year}]\": str(year) for year in range(1960, 2021)}\n",
    "\n",
    "# Rename the columns\n",
    "rename_df = indicator_filter.rename(columns=column_rename_mapping)\n",
    "\n",
    "rename_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column we don't need \n",
    "dropeddata=rename_df.drop(\"Series Code\",axis=1)\n",
    "transposed = dropeddata.pivot_table(index=['Country Name','Country Code'], columns=['Series Name'], aggfunc='first', fill_value=0)\n",
    "reset_1960=transposed[\"1960\"].reset_index()\n",
    "reset_1961=transposed[\"1961\"].reset_index()\n",
    "reset_1962=transposed[\"1962\"].reset_index()\n",
    "reset_1963=transposed[\"1963\"].reset_index()\n",
    "reset_1964=transposed[\"1964\"].reset_index()\n",
    "reset_1965=transposed[\"1965\"].reset_index()\n",
    "reset_1966=transposed[\"1966\"].reset_index()\n",
    "reset_1967=transposed[\"1967\"].reset_index()\n",
    "reset_1968=transposed[\"1968\"].reset_index()\n",
    "reset_1969=transposed[\"1969\"].reset_index()\n",
    "reset_1970=transposed[\"1970\"].reset_index()\n",
    "reset_1971=transposed[\"1971\"].reset_index()\n",
    "reset_1972=transposed[\"1972\"].reset_index()\n",
    "reset_1973=transposed[\"1973\"].reset_index()\n",
    "reset_1974=transposed[\"1974\"].reset_index()\n",
    "reset_1975=transposed[\"1975\"].reset_index()\n",
    "reset_1976=transposed[\"1976\"].reset_index()\n",
    "reset_1977=transposed[\"1977\"].reset_index()\n",
    "reset_1978=transposed[\"1978\"].reset_index()\n",
    "reset_1979=transposed[\"1979\"].reset_index()\n",
    "reset_1980=transposed[\"1980\"].reset_index()\n",
    "reset_1981=transposed[\"1981\"].reset_index()\n",
    "reset_1982=transposed[\"1982\"].reset_index()\n",
    "reset_1983=transposed[\"1983\"].reset_index()\n",
    "reset_1984=transposed[\"1984\"].reset_index()\n",
    "reset_1985=transposed[\"1985\"].reset_index()\n",
    "reset_1986=transposed[\"1986\"].reset_index()\n",
    "reset_1987=transposed[\"1987\"].reset_index()\n",
    "reset_1988=transposed[\"1988\"].reset_index()\n",
    "reset_1989=transposed[\"1989\"].reset_index()\n",
    "reset_1990=transposed[\"1990\"].reset_index()\n",
    "reset_1991=transposed[\"1991\"].reset_index()\n",
    "reset_1992=transposed[\"1992\"].reset_index()\n",
    "reset_1993=transposed[\"1993\"].reset_index()\n",
    "reset_1994=transposed[\"1994\"].reset_index()\n",
    "reset_1995=transposed[\"1995\"].reset_index()\n",
    "reset_1996=transposed[\"1996\"].reset_index()\n",
    "reset_1997=transposed[\"1997\"].reset_index()\n",
    "reset_1998=transposed[\"1998\"].reset_index()\n",
    "reset_1999=transposed[\"1999\"].reset_index()\n",
    "reset_2000=transposed[\"2000\"].reset_index()\n",
    "reset_2001=transposed[\"2001\"].reset_index()\n",
    "reset_2002=transposed[\"2002\"].reset_index()\n",
    "reset_2003=transposed[\"2003\"].reset_index()\n",
    "reset_2004=transposed[\"2004\"].reset_index()\n",
    "reset_2005=transposed[\"2005\"].reset_index()\n",
    "reset_2006=transposed[\"2006\"].reset_index()\n",
    "reset_2007=transposed[\"2007\"].reset_index()\n",
    "reset_2008=transposed[\"2008\"].reset_index()\n",
    "reset_2009=transposed[\"2009\"].reset_index()\n",
    "reset_2010=transposed[\"2010\"].reset_index()\n",
    "reset_2011=transposed[\"2011\"].reset_index()\n",
    "reset_2012=transposed[\"2012\"].reset_index()\n",
    "reset_2013=transposed[\"2013\"].reset_index()\n",
    "reset_2014=transposed[\"2014\"].reset_index()\n",
    "reset_2015=transposed[\"2015\"].reset_index()\n",
    "reset_2016=transposed[\"2016\"].reset_index()\n",
    "reset_2017=transposed[\"2017\"].reset_index()\n",
    "reset_2018=transposed[\"2018\"].reset_index()\n",
    "reset_2019=transposed[\"2019\"].reset_index()\n",
    "reset_2020=transposed[\"2020\"].reset_index()\n",
    "reset_1960['Year']=1960\n",
    "reset_1961['Year']=1961\n",
    "reset_1962['Year']=1962\n",
    "reset_1963['Year']=1963\n",
    "reset_1964['Year']=1964\n",
    "reset_1965['Year']=1965\n",
    "reset_1966['Year']=1966\n",
    "reset_1967['Year']=1967\n",
    "reset_1968['Year']=1968\n",
    "reset_1969['Year']=1969\n",
    "reset_1970['Year']=1970\n",
    "reset_1971['Year']=1971\n",
    "reset_1972['Year']=1972\n",
    "reset_1973['Year']=1973\n",
    "reset_1974['Year']=1974\n",
    "reset_1975['Year']=1975\n",
    "reset_1976['Year']=1976\n",
    "reset_1977['Year']=1977\n",
    "reset_1978['Year']=1978\n",
    "reset_1979['Year']=1979\n",
    "reset_1980['Year']=1980\n",
    "reset_1981['Year']=1981\n",
    "reset_1982['Year']=1982\n",
    "reset_1983['Year']=1983\n",
    "reset_1984['Year']=1984\n",
    "reset_1985['Year']=1985\n",
    "reset_1986['Year']=1986\n",
    "reset_1987['Year']=1987\n",
    "reset_1988['Year']=1988\n",
    "reset_1989['Year']=1989\n",
    "reset_1990['Year']=1990\n",
    "reset_1991['Year']=1991\n",
    "reset_1992['Year']=1992\n",
    "reset_1993['Year']=1993\n",
    "reset_1994['Year']=1994\n",
    "reset_1995['Year']=1995\n",
    "reset_1996['Year']=1996\n",
    "reset_1997['Year']=1997\n",
    "reset_1998['Year']=1998\n",
    "reset_1999['Year']=1999\n",
    "reset_2000['Year']=2000\n",
    "reset_2001['Year']=2001\n",
    "reset_2002['Year']=2002\n",
    "reset_2003['Year']=2003\n",
    "reset_2004['Year']=2004\n",
    "reset_2005['Year']=2005\n",
    "reset_2006['Year']=2006\n",
    "reset_2007['Year']=2007\n",
    "reset_2008['Year']=2008\n",
    "reset_2009['Year']=2009\n",
    "reset_2010['Year']=2010\n",
    "reset_2011['Year']=2011\n",
    "reset_2012['Year']=2012\n",
    "reset_2013['Year']=2013\n",
    "reset_2014['Year']=2014\n",
    "reset_2015['Year']=2015\n",
    "reset_2016['Year']=2016\n",
    "reset_2017['Year']=2017\n",
    "reset_2018['Year']=2018\n",
    "reset_2019['Year']=2019\n",
    "reset_2020['Year']=2020\n",
    "\n",
    "all_year = [reset_1960,reset_1961,reset_1962,reset_1963,reset_1964,reset_1965,reset_1966,reset_1967,reset_1968,reset_1969,reset_1970,reset_1971,reset_1972,reset_1973,reset_1974,reset_1975,reset_1976,reset_1977,reset_1978,reset_1979,reset_1980,reset_1981,reset_1982,reset_1983,reset_1984,reset_1985,reset_1986,reset_1987,reset_1988,reset_1989,reset_1990,reset_1991,reset_1992,reset_1993,reset_1994,reset_1995,reset_1996,reset_1997,reset_1998,reset_1999,reset_2000,reset_2001,reset_2002,reset_2003,reset_2004,reset_2005,reset_2006,reset_2007,reset_2008,\treset_2009,reset_2010,\treset_2011,reset_2012,reset_2013,reset_2014,reset_2015,reset_2016,\treset_2017,reset_2018,reset_2019,reset_2020]\n",
    "\n",
    "# Concatenate data\n",
    "concate_data= pd.concat(all_year)\n",
    "\n",
    "all_year_data =concate_data.replace(0, np.nan)\n",
    "\n",
    "\n",
    "# Rename column\n",
    "indicator_cleandata=all_year_data.rename(columns={\"Coverage of social insurance programs (% of population)\": \"social_insurance\",\n",
    "                              \"Series Name\":\"Series_name\",\n",
    "                              \"Country Name\":\"Country\",                  \n",
    "                              \"Country Code\":\"country_code\",\n",
    "                              \"Coverage of social protection and labor programs (% of population)\": \"social_protection\",\n",
    "                              \"Coverage of unemployment benefits and ALMP (% of population)\":\"unemployment_benefits\",\n",
    "                              \"Educational attainment, at least completed primary, population 25+ years, total (%) (cumulative)\": \"Educational_attainment\",\n",
    "                              \"Employment to population ratio, 15+, female (%) (national estimate)\":\"Female_employment\",\n",
    "                              \"Employment to population ratio, 15+, male (%) (national estimate)\": \"Male_employment\",\n",
    "                              \"GDP per capita (current US$)\": \"GDP_per_capita\",\n",
    "                              \"Labor force participation rate, female (% of female population ages 15+) (national estimate)\": \"Labor_force_rate_female\",\n",
    "                              \"Labor force participation rate, male (% of male population ages 15+) (national estimate)\": \"Labor_force_rate_male\",\n",
    "                              \"Labor force participation rate, total (% of total population ages 15+) (national estimate)\": \"Labor_force_total\",\n",
    "                              \"Labor force with basic education (% of total working-age population with basic education)\":\"Labour_force_with_basic_education\",\n",
    "                              \"Labor force with basic education, female (% of female working-age population with basic education)\":\"Labour_force_with_basic_education_female\",\n",
    "                              \"Life expectancy at birth, female (years)\":\"life_expectancy_female\",\"Life expectancy at birth, male (years)\": \"Life_expectancy_male\",\n",
    "                              \"Life expectancy at birth, total (years)\":\"Life_expectancy_total\",\"Population, total\":\"Total_population\",\n",
    "                              \"Suicide mortality rate (per 100,000 population)\":\"Suicide_mortality_rate_per_100k\",\n",
    "                              \"Suicide mortality rate, female (per 100,000 female population)\":\"Suicide_mortality_rate_per_100k_female\",\n",
    "                              \"Suicide mortality rate, male (per 100,000 male population)\":\"Suicide_mortality_rate_per_100k_male\",\n",
    "                              \"Unemployment with basic education (% of total labor force with basic education)\":\"unemployment_with_basic_education_total\",\n",
    "                              \"Unemployment with basic education, female (% of female labor force with basic education)\":\"Unemployment_with_basic_education_female\",\n",
    "                              \"Unemployment with basic education, male (% of male labor force with basic education)\":\"Unemployment_with_basic_education_male\"})\n",
    "indicator_cleandata.to_csv('Data/clean_indicator.csv')\n",
    "indicator_cleandata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about the data\n",
    "\n",
    "indicator_cleandata.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we doing the ML we tried to see If there is any coorelation between factors on \"Suicide_mortality_rate_per_100k\" \n",
    "indicator_corr= pd.get_dummies(indicator_cleandata).corr()\n",
    "indicator_corr_treatment= indicator_corr[\"Suicide_mortality_rate_per_100k\"]\n",
    "\n",
    "print(\"Display items with correlation coefficient of 0.3 or more and -0.3 or less\")\n",
    "# Get values with a correlation coefficient of 0.2 or more and -0.2 or less\n",
    "target_cc_value = 0.4\n",
    "\n",
    "print(\"Positive correlation\")\n",
    "display(indicator_corr_treatment[indicator_corr_treatment >= target_cc_value])\n",
    "print(\"Negative correlation\")\n",
    "display(indicator_corr_treatment[indicator_corr_treatment <= (-1*target_cc_value)])\n",
    "\n",
    "df_indexs = indicator_corr[(indicator_corr[\"Suicide_mortality_rate_per_100k\"] >= target_cc_value) | (indicator_corr[\"Suicide_mortality_rate_per_100k\"] <= (-1 * target_cc_value))].index\n",
    "\n",
    "#print(indicator_corr)\n",
    "df_cc_target=indicator_corr.loc[df_indexs,df_indexs]\n",
    "plt.figure(figsize=(10, 8)) #heatmap size\n",
    "sns.heatmap(df_cc_target, annot=True, linewidths=.5)\n",
    "plt.savefig(\"static/images/corr.png\", bbox_inches = \"tight\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot on the correlation matrix\n",
    "g = sns.pairplot(df_cc_target)\n",
    "g.map_upper(sns.scatterplot, s=100,color = 'darkred')\n",
    "g.map_lower(sns.kdeplot)\n",
    "g.map_diag(sns.kdeplot, lw=2)\n",
    "plt.savefig(\"static/images/corrmatt.png\", bbox_inches = \"tight\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data\n",
    "# Drop the \"Year\" column\n",
    "ready_data = indicator_cleandata.drop(\"Year\", axis=1)\n",
    "\n",
    "# Group by 'Country' and calculate mean only for numeric columns\n",
    "numeric_data = ready_data.select_dtypes(include=['number'])\n",
    "df = numeric_data.groupby(ready_data['Country']).mean()\n",
    "\n",
    "# Drop rows with missing values and reset index\n",
    "clean = df.dropna().reset_index()\n",
    "\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3A. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features (columns)\n",
    "y = clean[\"Suicide_mortality_rate_per_100k\"].values\n",
    "data = clean.drop(\"Country\",axis=1).drop(\"Suicide_mortality_rate_per_100k\",axis=1).drop(\"Suicide_mortality_rate_per_100k_female\",axis=1).drop(\"Suicide_mortality_rate_per_100k_male\",axis=1).drop(\"Total_population\",axis=1)\n",
    "X=data.values\n",
    "x_columns = data.iloc[:,1:].columns\n",
    "x_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "# Train the Model (Linear regression)\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a polt on the training and test scores\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\",s=150, label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\",s=150, label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.savefig(\"static/images/Linear_re.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "r2 = model.score(X_test, y_test)\n",
    "MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "print(f\"MSE: {MSE}, R2: {r2}, MAE: {MAE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# Plot the data \n",
    "plt.xlabel(\"Features\",fontsize = 14)\n",
    "plt.ylabel(\"Score\",fontsize = 14)\n",
    "plt.title(\"Feature Importance\",fontsize = 20)\n",
    "plt.savefig(\"static/images/Linear_re_importance.png\", bbox_inches = \"tight\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/linear_Regression.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3B. Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.reshape(-1, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "model=DecisionTreeRegressor(random_state = 0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "r2 = model.score(X_test, y_test)\n",
    "MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "print(f\"MSE: {MSE}, R2: {r2}, MAE: {MAE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/Dec_Regression.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3C. Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_score = regressor.score(X_train, y_train)\n",
    "testing_score = regressor.score(X_test, y_test)\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = regressor.predict(X_test)\n",
    "MSE = mean_squared_error(y_test, predictions)\n",
    "r2 = regressor.score(X_test, y_test)\n",
    "MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "print(f\"MSE: {MSE}, R2: {r2}, MAE: {MAE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/SVR_Regression.sav'\n",
    "joblib.dump(regressor, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D. Logistic Regression\n",
    "\n",
    "For our logistic regression model we group our dependent variable (\"Suicide_mortality_rate_per_100k\") in two group below and above the mean the mean value( 11.5) of Suicide mortality rate per 100,000 at the national level. Suicide mortality rate above 11.5 would be high and below 11.5 would be low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = clean.drop(\"Country\",axis=1).drop(\"Suicide_mortality_rate_per_100k\",axis=1).drop(\"Suicide_mortality_rate_per_100k_female\",axis=1).drop(\"Suicide_mortality_rate_per_100k_male\",axis=1).drop(\"Total_population\",axis=1)\n",
    "X=data.values\n",
    "x_columns = data.iloc[:,1:].columns\n",
    "x_columns\n",
    "y = clean[\"Suicide_mortality_rate_per_100k\"]\n",
    "def score(i):\n",
    "    if i < 11.5: return \"Low\"\n",
    "    if i > 11.5: return \"High\"\n",
    "li = map(lambda x: \"{1}\".format(x, score(x)), y)\n",
    "y2=[]\n",
    "for i in li:\n",
    "    y2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use keyword arguments for sns.boxplot\n",
    "sns.boxplot(x=y2, y=clean['social_insurance'])\n",
    "\n",
    "# Add scatter plot\n",
    "plt.scatter(y2, clean['social_insurance'], color='red', alpha=0.5)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel(\"Suicide mortality rate per 100k\", fontsize=14)\n",
    "plt.ylabel(\"Social Insurance\", fontsize=14)\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Social Insurance Versus\\nSuicide mortality rate per 100,000 people\", fontsize=20)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"static/images/Social_Insurance.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Use keyword arguments for sns.boxplot\n",
    "sns.boxplot(x=y2, y=clean['Labour_force_with_basic_education'])\n",
    "\n",
    "# Add scatter plot\n",
    "plt.scatter(y2, clean['Labour_force_with_basic_education'], color='red', alpha=0.5)\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel(\"Suicide mortality rate per 100k\", fontsize=14)\n",
    "plt.ylabel(\"Labour force with basic education\", fontsize=14)\n",
    "\n",
    "# Add a title\n",
    "plt.title(\"Labour Force with Basic Education Versus \\nSuicide Mortality Rate per 100,000 People\", fontsize=20)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"static/images/Labour_force_with_basic_education.png\", bbox_inches=\"tight\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm=pd.get_dummies(y2, drop_first = False)\n",
    "norm_y=norm[\"High\"]\n",
    "norm_y=pd.DataFrame(norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, norm_y, random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "### Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "### Precision\n",
    "precision = precision_score(y_test, predictions)\n",
    "### F1\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print('Accuracy：{0:.2f}%'.format(accuracy * 100))\n",
    "print('Recall：{0:.2f}%'.format(recall * 100))\n",
    "print('Precision：{0:.2f}%'.format(precision * 100))\n",
    "print('F1：{0:.2f}%'.format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "viz = ClassificationReport(LogisticRegression(),cmap=\"PuBu\")\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()\n",
    "viz.show(outpath=\"static/images/logistic_befor_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "plt.savefig(\"static/images/logistic_importance.png\", bbox_inches = \"tight\")\n",
    "plt.xlabel(\"Features\",fontsize = 14)\n",
    "plt.ylabel(\"Score\",fontsize = 14)\n",
    "plt.title(\"Feature Importance\",fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10],\n",
    "              'penalty': [\"l1\", \"l2\"]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training score:\n",
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing score:\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "viz = ClassificationReport(LogisticRegression(),cmap=\"PuBu\")\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()\n",
    "viz.show(outpath=\"static/images/logisticregression_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/logistic_Regression.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3E. Support Vector Machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, norm_y, random_state=42, test_size = 0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_minmax = MinMaxScaler().fit(X_train)\n",
    "X_train_minmax = X_minmax.transform(X_train)\n",
    "X_test_minmax = X_minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_minmax, y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_minmax, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training score:\n",
    "grid.score(X_train_minmax, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing score:\n",
    "grid.score(X_test_minmax, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "### Recall\n",
    "recall = recall_score(y_test, predictions)\n",
    "### Precision\n",
    "precision = precision_score(y_test, predictions)\n",
    "### F1\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print('Accuracy：{0:.2f}%'.format(accuracy * 100))\n",
    "print('Recall：{0:.2f}%'.format(recall * 100))\n",
    "print('Precision：{0:.2f}%'.format(precision * 100))\n",
    "print('F1：{0:.2f}%'.format(f1 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Classification Report.\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "viz = ClassificationReport(SVC(),cmap=\"PuBu\")\n",
    "viz.fit(X_train_minmax, y_train)\n",
    "viz.score(X_test_minmax, y_test)\n",
    "viz.finalize()\n",
    "viz.show(outpath=\"static/images/svm_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "viz = FeatureImportances(model,size=(700, 500),color='b', align='center')\n",
    "viz.fit(X_train_minmax, y_train)\n",
    "viz.show(outpath=\"static/images/svm_featureimportance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/logistic_Regression.sav'\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3F. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion=\"gini\", max_depth=None, min_samples_split=2, min_samples_leaf=2, random_state=1234)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"train score=\", clf.score(X_train, y_train))\n",
    "print(\"test score=\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "plt.savefig(\"static/images/decision_tree_importance.png\", bbox_inches = \"tight\")\n",
    "plt.xlabel(\"Features\",fontsize = 14)\n",
    "plt.ylabel(\"Score\",fontsize = 14)\n",
    "plt.title(\"Feature Importance\",fontsize = 20)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "tree.plot_tree(clf,\n",
    "               filled=True, \n",
    "               rounded=True,\n",
    "               fontsize=9) \n",
    "plt.savefig(\"static/images/tree.png\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/DecisionTree.sav'\n",
    "joblib.dump(clf, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3G. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, norm_y, random_state=42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data Score: {randomforest.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {randomforest.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(randomforest.feature_importances_, x_columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [250, 300, 350],\n",
    "              'max_depth': [125, 150, 175]}\n",
    "grid = GridSearchCV(randomforest, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction and save to variable for report.\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "viz = ClassificationReport(RandomForestClassifier(),cmap=\"PuBu\")\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.finalize()\n",
    "viz.show(outpath=\"static/images/randomforest_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "viz = FeatureImportances(randomforest,size=(700, 500),color='b', align='center')\n",
    "viz.fit(X_train, y_train)\n",
    "viz.show(outpath=\"static/images/rf_featureimportance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "filename = 'model_sav/randomforest.sav'\n",
    "joblib.dump(randomforest, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seed = 7\n",
    "\n",
    "# Prepare models\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier()))\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('DeT', DecisionTreeClassifier()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    # Ensure shuffle=True for random_state to work\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=seed, shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X, y2, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = f\"{name}: {cv_results.mean():.4f} ({cv_results.std():.4f})\"\n",
    "    print(msg)\n",
    "\n",
    "# Boxplot algorithm comparison\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.boxplot(results, patch_artist=True)\n",
    "plt.title('Algorithm Comparison', fontsize=20)\n",
    "plt.xlabel(\"Models\", fontsize=14)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "plt.xticks(ticks=range(1, len(names) + 1), labels=names)\n",
    "plt.savefig(\"static/images/compare.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we used various machine learning models, trained and tested the data to see the models ability to predict suicide mortality rate from various macro socio-economic factors in the national level. We used linear regression, logistic regression, support vector machine, decision tree, and random forest model. We note differences in accuracy (and thus, effectiveness), the models has toward the entire dataset. We noticed similar reapearing patterns that we knew would serve of importance when predicting suicide mortality rate from various macro socio-economic factors.\n",
    "\n",
    "The first step in our analysis was to clean, and preprocess our dataset to make ready for machine learning analysis. We cleaned, explored and visualized the data. The pre-processing normalize the data for ML analysis.\n",
    "\n",
    "Before the ML analysis we tried to see If there is any coorelation between factors on Suicide mortality rate per 100,000 people. We have found a positive(0.5) correlation between Suicide mortality rate, and coverage of social insurance programs.\n",
    "\n",
    "Previous research identified that there is a solid association between economic strain and suicide, little attention has been paid to how specific welfare policies that are designed to alleviate economic strain may influence suicide rates. There is a growing body of research that is using an institutional approach to demonstrate the role of welfare-state policies in the distribution of health. However, this perspective has not been applied yet to the investigation of suicide.(Simone Rambotti 2019) \n",
    "\n",
    "We have also found a negative(-0.5) correlation between suicide mortality rate (% of population) and coverage of labor force with basic education (% of total working-age population with basic education). When Countries having a population at least with a basic education is higher it negatively relate with Suicide mortality rate. Which means when the poulation obtained at least basic education increases suicide mortality rate decreases.\n",
    "\n",
    "\n",
    "The first three models we executed are linear regression, decision tree regression, and support vector regression (SVR) to estimate the suicide mortality rate (continous dependent variable) on the estimator variables. The result from this three models showed that lower R-Squared value(R2), and higher mean square error(MSE). However, comparing the above three models decision tree regression explained the dependent variable(suicide mortality rate) better by the independent variable(predictor variables) with R-Squared value 0.24 and mean square error (MSE) 87.11.\n",
    "\n",
    "To test the other models we grouped our continous dependent variable (\"Suicide_mortality_rate_per_100k\") in to two groups, below and above the mean value( 11.5). Suicide mortality rate above 11.5 would be high and below 11.5 would be low. Afterward we executed logistic regression, support Vector Machine, decision tree, and random forest model. The finding from this models showed that the models accuracy to peredict the dependent variable is low but, compering the models support vector machine explain the data very well after grid search with 72.2 accuracy.\n",
    "\n",
    "In conclusion, mental helath and suicide is an important cause to study because we are losing so many lifes in the world because of suicide. Our project focused identifying macro level socio-economic factors that would cause the problem, and we belive that if socio-economic factors, and countries polices towards mental health changed the issue will be solved with some point. However, the issue is too complex, and it depends on the indviduals subjective expiriance, so a collaborative, and a comprehensive approach is important to address the issue. Specific to this project we have been challenged with the data quality (so many null values), we hope if the models applied with a better data we can see more tangible factors that would predict the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
